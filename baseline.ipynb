{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KateiKyoushi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If first time, uncomment below lines\n",
    "\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(file_name, text):\n",
    "    with open(file_name, \"w+\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFParser:\n",
    "    def __init__(self, path) -> None:\n",
    "        self.path = path\n",
    "        self.text = self.parse_text()\n",
    "\n",
    "    def parse_text(self):\n",
    "        pdf_reader = PdfReader(self.path)\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "    def get_keywords(self, num):\n",
    "        keywords = []\n",
    "        words = word_tokenize(self.text)\n",
    "\n",
    "        # Remove punctuation\n",
    "        words = [word for word in words if word.isalnum()]\n",
    "\n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        words = [word for word in words if not word.lower() in stop_words]\n",
    "\n",
    "        # Lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "        # Get top-{num} most common words\n",
    "        word_freq = Counter(words)\n",
    "        keywords = word_freq.most_common(num)\n",
    "\n",
    "        str_keywords = \", \".join([w[0] for w in keywords])\n",
    "\n",
    "        return f\"Top-{num} keywords: {str_keywords}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PDFParser(\"paper/Attention Is All You Need.pdf\")\n",
    "test.get_keywords(5)\n",
    "test.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_prompt(content, keywords):\n",
    "    context = f\"\"\"\n",
    "    You are a highly skilled instructor tasked with creating a structured course outline based on provided keywords.\n",
    "    Using these keywords, design a comprehensive course that encompasses all key concepts in all materials.\n",
    "    \"\"\"\n",
    "\n",
    "    context += f\"\"\"Keywords: {keywords}\"\"\"\n",
    "    context += f\"\"\"Materials: {content}\"\"\"\n",
    "\n",
    "    context += f\"\"\"\n",
    "    Output Requirement: Generate a course outline formatted in Markdown, strictly adhering to the example format provided below.\n",
    "    Each lesson should include a lesson name (lesson_name) and a concise description (lesson_abstract).\n",
    "    Use different levels of headings, bold and italic format to highlight important topics.\n",
    "\n",
    "    Example Format:\n",
    "    # lesson_name\n",
    "    lesson_abstract\n",
    "    \n",
    "    ## important topic 1\n",
    "    - important topic 1 breakdown\n",
    "    explanation of the topic\n",
    "    \n",
    "    ### key concept explanation\n",
    "    explanation of the concept\n",
    "    \n",
    "    ## important topic 2\n",
    "    explanation of the topic\n",
    "    \n",
    "    ### important topic 2 breakdown\n",
    "    - important topic 2 breakdown\n",
    "    explanation of the topic\n",
    "    ...\n",
    "\n",
    "    Begin designing the course now.\"\"\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(content):\n",
    "    context = f\"\"\"\n",
    "    Use provided Course Outline, refine and elaborate on each topic. \n",
    "    Output your response combining the given Course Outline and your generated content.\n",
    "    \"\"\"\n",
    "\n",
    "    context += f\"\"\"Materials: {content}\"\"\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content(outline, time):\n",
    "    context = f\"\"\"\n",
    "    Using the provided course outline, create a study plan within the specified time frame. \n",
    "    Detail the key topics and suggested study sessions per hours based on the material's structure and complexity. \n",
    "    Ensure the plan is tailored to your specific learning preferences and available study hours per week. \n",
    "    \"\"\"\n",
    "\n",
    "    context += f\"\"\"Course Outline: {outline}\"\"\"\n",
    "    context += f\"\"\"Time Frame: {time}\"\"\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elaborate(schedule):\n",
    "    context = f\"\"\"\n",
    "    Using the provided study plan, elaborate on each concept mentioned. \n",
    "    Include detailed explanations, relevant examples, and practical applications to ensure a comprehensive understanding of each topic. \n",
    "    This expanded content should assist in preparing for in-depth discussions, exams, or practical implementations related to the course material.\n",
    "    \"\"\"\n",
    "\n",
    "    context += f\"\"\"Study Plan: {schedule}\"\"\"\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 传文件 (解析成文本)\n",
    "2. 给出大纲和题目数\n",
    "3. 解释一个概念，给出一个问题，二（多）选一\n",
    "4. 判断用户是否答对，如果答对，继续下一题；如果答错，解释错误原因\n",
    "5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = test.get_keywords(15)\n",
    "# prompt = compile_prompt(test.text, keywords)\n",
    "# response = get_response(prompt)\n",
    "# create_file(\"1.md\", response)\n",
    "# schedule = get_response(generate_content(response, \"3 days\"))\n",
    "# create_file(\"2.md\", schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2.md\", \"r\") as f:\n",
    "    schedule = \" \".join(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(elaborate(schedule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file(\"3.md\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
